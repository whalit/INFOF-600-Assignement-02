{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77115099",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834504d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 2: Pandas\n",
    "## Cleaning and Exploring Data with Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b743173a",
   "metadata": {},
   "source": [
    "## Assignment Modalities -- IMPORTANT -- READ CAREFULLY\n",
    "\n",
    "This assignment contains a number of question that are worth 1--2 points each, as seen at the table below. At each question, you need to fill in the missing code, which is denoted by `...`. In some cases, you could write a single line of code, in other cases you might want to use more lines to achieve the desired outcome. **NOTE** that you should not change any code segment except the part denoted as `...`, as it might interfere with the auto grading, see below.\n",
    "\n",
    "The assignment will be automatically graded by running tests on the provided code. Some of the tests are available after each cell with missing code. To run the automatic grader, you need to have otter-grader installed. This is not mandatory, but advised, so that you can check the validity of your answers. **NOTE** that for the final grading we will run additional tests not available in this notebook.\n",
    "\n",
    "The installation instructions for otter-grader are here:  \n",
    "<https://otter-grader.readthedocs.io/en/latest/#installation>\n",
    "\n",
    "**IMPORTANT**: First rename this notebook to `groupXX_assignment2.ipynb`, where `XX` should be your group number for the 2nd assignment, e.g., `01`. For the autograder to work locally, make sure that in the initialization of otter the right notebook name is passed:\n",
    "```\n",
    "grader = otter.Notebook(\"groupXX_assignment2.ipynb\")\n",
    "```\n",
    "\n",
    "**Note**: Installing the otter-grader is not necessary. All tests visible to you are included in the notebook as assertions.\n",
    "\n",
    "After finishing the assignment, you should submit this notebook named `groupXX_assignment2.ipynb`.\n",
    "\n",
    "\n",
    "## Score Breakdown \n",
    "Question | Points\n",
    "--- | ---\n",
    "1a | 1\n",
    "1b | 2\n",
    "1c | 1\n",
    "2a | 2\n",
    "2b | 1\n",
    "2ci | 1\n",
    "2cii | 1\n",
    "2d | 2\n",
    "2e | 2\n",
    "3a | 1\n",
    "3bi | 2\n",
    "3bii | 2\n",
    "3ci | 1\n",
    "3cii | 1\n",
    "3ciii | 1\n",
    "3civ | 1\n",
    "4a | 2\n",
    "4b | 3\n",
    "4c | 2\n",
    "Total | 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68306c0c",
   "metadata": {},
   "source": [
    "\n",
    "## Assignment Objective\n",
    "\n",
    "In this homework, we will investigate restaurant food safety scores for restaurants in San Francisco. The scores and violation information have been [made available by the San Francisco Department of Public Health](https://data.sfgov.org/Health-and-Social-Services/Restaurant-Scores-LIVES-Standard/pyih-qa8i). The main goal for this assignment is to walk through the process of Data Cleaning and EDA. \n",
    "\n",
    "\n",
    "As we clean and explore these data, you will gain practice with:\n",
    "* Reading simple csv files and using Pandas\n",
    "* Working with data at different levels of granularity\n",
    "* Identifying the type of data collected, missing values, anomalies, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60df375",
   "metadata": {},
   "source": [
    "## Before You Start\n",
    "\n",
    "For each question in the assignment, please write down your answer in the answer cell(s) right below the question. \n",
    "\n",
    "We understand that it is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run codes, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors when we run the autograder, and it will sometimes cause a failure to generate the PDF file.\n",
    "\n",
    "**Important note: The local autograder tests will not be comprehensive. You can pass the automated tests in your notebook but still fail tests in the autograder.** Please be sure to check your results carefully.\n",
    "\n",
    "Finally, unless we state otherwise, try to avoid using python for loops or list comprehensions.  The majority of this assignment can be done using builtin commands in Pandas and numpy.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1b48a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import os # Used to interact with the file system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82ef4a",
   "metadata": {},
   "source": [
    "## Obtaining the Data\n",
    "\n",
    "### File Systems and I/O\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e55a1d",
   "metadata": {},
   "source": [
    "In general, we will focus on using python commands to investigate files.  However, it can sometimes be easier to use shell commands in your local operating system.  The following cells demonstrate how to do this.\n",
    "\n",
    "**NOTE** Do not change the location of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c91485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('./data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a376d",
   "metadata": {},
   "source": [
    "## Loading Food Safety Data\n",
    "\n",
    "We have data, but we don't have any specific questions about the data yet. Let's focus on understanding the structure of the data; this involves answering questions such as:\n",
    "\n",
    "* Is the data in a standard format or encoding?\n",
    "* Is the data organized in records?\n",
    "* What are the fields in each record?\n",
    "\n",
    "Let's start by looking at the contents of the `data` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43286365",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Looking At the Data Files\n",
    "\n",
    "The following codeblocks are setup. Simply run the cells; **do not modify them**. Question 1a is where you will start to write code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a52ed",
   "metadata": {},
   "source": [
    "You should see five CSV files. Open up `legend.csv` to see its contents.  You should see something that looks like:\n",
    "\n",
    "    \"Minimum_Score\",\"Maximum_Score\",\"Description\"\n",
    "    0,70,\"Poor\"\n",
    "    71,85,\"Needs Improvement\"\n",
    "    86,90,\"Adequate\"\n",
    "    91,100,\"Good\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5ee9e",
   "metadata": {},
   "source": [
    "## Reading in and Verifying Data\n",
    "\n",
    "Based on the above information, let's attempt to load `bus.csv`, `ins2vio.csv`, `ins.csv`, and `vio.csv` into pandas dataframes with the following names: `bus`, `ins2vio`, `ins`, and `vio` respectively.\n",
    "\n",
    "*Note:* Because of character encoding issues one of the files (`bus`) will require an additional argument `encoding='ISO-8859-1'` when calling `pd.read_csv`. At some point in your future, you should read all about [character encodings](https://diveintopython3.problemsolving.io/strings.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to directory containing data\n",
    "\n",
    "bus = pd.read_csv(data_dir/'bus.csv', encoding='ISO-8859-1')\n",
    "ins2vio = pd.read_csv(data_dir/'ins2vio.csv')\n",
    "ins = pd.read_csv(data_dir/'ins.csv')\n",
    "vio = pd.read_csv(data_dir/'vio.csv')\n",
    "\n",
    "#This code is essential for the autograder to function properly. Do not edit\n",
    "ins_test = ins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9afbbd",
   "metadata": {},
   "source": [
    "Now that you've read in the files, let's try some `pd.DataFrame` methods ([docs](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.html)).\n",
    "Use the `DataFrame.head` method to show the top few lines of the `bus`, `ins`, and `vio` dataframes. To show multiple return outputs in one single cell, you can useÂ `display()`. Currently, running the cell below will display the first few lines of the `bus` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6efab7e",
   "metadata": {},
   "source": [
    "The `DataFrame.describe` method can also be handy for computing summaries of numeric columns of our dataframes. Try it out with each of our 4 dataframes. Below, we have used the method to give a summary of the `bus` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee89336",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd963de",
   "metadata": {},
   "source": [
    "Now, we perform some sanity checks for you to verify that the data was loaded with the correct structure. Run the following cells to load some basic utilities (you do not need to change these at all):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b04fd6",
   "metadata": {},
   "source": [
    "First, we check the basic structure of the data frames you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66efdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(bus.columns == ['business id column', 'name', 'address', 'city', 'state', 'postal_code',\n",
    "                           'latitude', 'longitude', 'phone_number'])\n",
    "assert 6250 <= len(bus) <= 6260\n",
    "\n",
    "assert all(ins.columns == ['iid', 'date', 'score', 'type'])\n",
    "assert 26660 <= len(ins) <= 26670\n",
    "\n",
    "assert all(vio.columns == ['description', 'risk_category', 'vid'])\n",
    "assert 60 <= len(vio) <= 65\n",
    "\n",
    "assert all(ins2vio.columns == ['iid', 'vid'])\n",
    "assert 40210 <= len(ins2vio) <= 40220"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953a708",
   "metadata": {},
   "source": [
    "Next we'll check that the statistics match what we expect. The following are hard-coded statistical summaries of the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee64eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_summary = pd.DataFrame(**{'columns': ['business id column', 'latitude', 'longitude'],\n",
    " 'data': {'business id column': {'50%': 75685.0, 'max': 102705.0, 'min': 19.0},\n",
    "  'latitude': {'50%': -9999.0, 'max': 37.824494, 'min': -9999.0},\n",
    "  'longitude': {'50%': -9999.0,\n",
    "   'max': 0.0,\n",
    "   'min': -9999.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "ins_summary = pd.DataFrame(**{'columns': ['score'],\n",
    " 'data': {'score': {'50%': 76.0, 'max': 100.0, 'min': -1.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "vio_summary = pd.DataFrame(**{'columns': ['vid'],\n",
    " 'data': {'vid': {'50%': 103135.0, 'max': 103177.0, 'min': 103102.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print('What we expect from your Businesses dataframe:')\n",
    "display(bus_summary)\n",
    "print('What we expect from your Inspections dataframe:')\n",
    "display(ins_summary)\n",
    "print('What we expect from your Violations dataframe:')\n",
    "display(vio_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a3728",
   "metadata": {},
   "source": [
    "The code below defines a testing function that we'll use to verify that your data has the same statistics as what we expect. Run these cells to define the function. The `df_allclose` function has this name because we are verifying that all of the statistics for your dataframe are close to the expected values. Why not `df_allequal`? It's a bad idea in almost all cases to compare two floating point values like 37.780435, as rounding error can cause spurious failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run this cell to load this utility comparison function that we will use in various\n",
    "tests below (both tests you can see and those we run internally for grading).\n",
    "\n",
    "Do not modify the function in any way.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def df_allclose(actual, desired, columns=None, rtol=5e-2):\n",
    "    \"\"\"Compare selected columns of two dataframes on a few summary statistics.\n",
    "    \n",
    "    Compute the min, median and max of the two dataframes on the given columns, and compare\n",
    "    that they match numerically to the given relative tolerance.\n",
    "    \n",
    "    If they don't match, an AssertionError is raised (by `numpy.testing`).\n",
    "    \"\"\"    \n",
    "    # summary statistics to compare on\n",
    "    stats = ['min', '50%', 'max']\n",
    "    \n",
    "    # For the desired values, we can provide a full DF with the same structure as\n",
    "    # the actual data, or pre-computed summary statistics.\n",
    "    # We assume a pre-computed summary was provided if columns is None. In that case, \n",
    "    # `desired` *must* have the same structure as the actual's summary\n",
    "    if columns is None:\n",
    "        des = desired\n",
    "        columns = desired.columns\n",
    "    else:\n",
    "        des = desired[columns].describe().loc[stats]\n",
    "\n",
    "    # Extract summary stats from actual DF\n",
    "    act = actual[columns].describe().loc[stats]\n",
    "\n",
    "    return np.allclose(act, des, rtol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60570b86",
   "metadata": {},
   "source": [
    "We will now explore each file in turn, including determining its granularity and primary keys and exploring many of the variables individually. Let's begin with the businesses file, which has been read into the `bus` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5b56a3",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 1a: Examining the Business Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557ac70",
   "metadata": {},
   "source": [
    "From its name alone, we expect the `bus.csv` file to contain information about the restaurants. Let's investigate the granularity of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6566c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20662d38",
   "metadata": {},
   "source": [
    "The `bus` dataframe contains a column called `business id column` which probably corresponds to a unique business id.  However, we will first rename that column to `bid` for simplicity.\n",
    "\n",
    "**Note**: In practice we might want to do this renaming when the table is loaded but for grading purposes we will do it here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a867a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = bus.rename(columns={\"business id column\": \"bid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651eb1d",
   "metadata": {},
   "source": [
    "Examining the entries in `bus`, is the `bid` unique for each record (i.e. each row of data)? Your code should compute the answer, i.e. don't just hard code `True` or `False`.\n",
    "\n",
    "Hint: use `value_counts()` or `unique()` to determine if the `bid` series has any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5420e6f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "is_bid_unique = ...\n",
    "\n",
    "is_bid_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a228c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(is_bid_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ae2ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0755a364",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 1b\n",
    "\n",
    "We will now work with some important fields in `bus`.\n",
    "\n",
    "1. Assign `top_names` to a list containing the top 5 most frequently used business names, from most frequent to least frequent.\n",
    "2. Assign `top_addresses` to a list containing the top 5 addressses where businesses are located, from most popular to least popular.\n",
    "\n",
    "Hint: you may find `value_counts()` helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9fb92",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "top_names = ...\n",
    "top_addresses = ...\n",
    "\n",
    "top_names, top_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a0973",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert len(top_names) == 5\n",
    "assert top_names[0] == \"Peet's Coffee & Tea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce6690",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4136369",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 1c\n",
    "\n",
    "Based on the above exploration, what does each record represent?\n",
    "\n",
    "A. \"One location of a restaurant.\"\n",
    "B. \"A chain of restaurants.\"\n",
    "C. \"A city block.\"\n",
    "\n",
    "Answer in the following cell. Your answer should be a string, either `\"A\"`, `\"B\"`, or `\"C\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2987b13",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# What does each record represent?  Valid answers are:\n",
    "#    A \"One location of a restaurant.\"\n",
    "#    B \"A chain of restaurants.\"\n",
    "#    C \"A city block.\"\n",
    "q1c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db8085",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(q1c in set([\"A\", \"B\", \"C\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710ff14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5e00f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "# 2: Cleaning the Business Data Postal Codes\n",
    "\n",
    "The business data contains postal code information that we can use to aggregate the ratings over regions of the city.  Let's examine and clean the postal code field.\n",
    "\n",
    "*NOTE*: In USA, postal codes have 5 digits, like `90210`. There is also a more specific or full postal code that has four additional digits, like `90210-1007`.\n",
    "\n",
    "The postal code (sometimes also called a ZIP code) partitions the city into regions:\n",
    "\n",
    "<img src=\"https://www.usmapguide.com/wp-content/uploads/2019/03/printable-san-francisco-zip-code-map.jpg\" alt=\"ZIP Code Map\" style=\"width: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb265f39",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4c4a09f1ecf2f4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 2a\n",
    "\n",
    "How many restaurants are in each ZIP code? \n",
    "\n",
    "In the cell below, create a **series** where the index is the postal code and the value is the number of records with that postal code in descending order of count. You may need to use `groupby()`, `size()`, or `value_counts()`. Do you notice any odd/invalid zip codes?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669d079",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2151d673e6c36a1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "zip_counts = ...\n",
    "print(zip_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b339ba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(zip_counts) == pd.Series)\n",
    "assert(zip_counts[\"94103\"] == 562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3affb83",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ef6c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 2b\n",
    "\n",
    "Answer the following question about the `postal_code` column in the `bus` dataframe.\n",
    "\n",
    "   \n",
    "1. What Python data type is used to represent a ZIP code?  \n",
    "    A. `str`  \n",
    "    B. `int`  \n",
    "    C. `bool`  \n",
    "    D. `float`\n",
    "\n",
    "*Note*: ZIP codes and postal codes are the same thing.\n",
    "\n",
    "Please write your answers in the cell below. Your answer should be a string, either `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f37c92",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# What Python data type is used to represent a ZIP code? \n",
    "q2b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b6766",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(q2b in set([\"A\", \"B\", \"C\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59138a6c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a2d5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 2c\n",
    "\n",
    "In question 2a we noticed a large number of potentially invalid ZIP codes (e.g., \"Ca\").  These are likely due to data entry errors.  To get a better understanding of the potential errors in the zip codes we will:\n",
    "\n",
    "1. Import a list of valid San Francisco ZIP codes by using `pd.read_json` to load the file `data/sf_zipcodes.json` and extract a **series** of type `str` containing the valid ZIP codes.  *Hint: set `dtype` when invoking `read_json`.*\n",
    "1. Construct a `DataFrame` containing only the businesses which DO NOT have valid ZIP codes.  You will probably want to use the `Series.isin` function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cfb8ce",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Step 1**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ci\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cef166",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "valid_zips = ...\n",
    "\n",
    "valid_zips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d8180",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert( (valid_zips.dtype == object) | (valid_zips.dtype == pd.StringDtype())) \n",
    "assert(type(valid_zips) == pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f5ce8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2ci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82796d",
   "metadata": {
    "editable": false
   },
   "source": [
    "**Step 2**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2cii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28fc8b",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# has_valid_zip should be a boolean array\n",
    "# A True value would indicate the business has a valid ZIP code\n",
    "\n",
    "has_valid_zip = ...\n",
    "\n",
    "invalid_zip_bus = ...\n",
    "invalid_zip_bus.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009062c6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(invalid_zip_bus) == pd.DataFrame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f2117",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2cii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98669f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 2d\n",
    "\n",
    "In the previous question, many of the businesses had a common invalid postal code that was likely used to encode a MISSING postal code.  Do they all share a potentially \"interesting address\"?\n",
    "\n",
    "In the following cell, construct a **series** that counts the number of businesses at each `address` that have this single likely MISSING postal code value.  Order the series in descending order by count. \n",
    "\n",
    "After examining the output, please answer the following question (2e) by filling in the appropriate variable. If we were to drop businesses with MISSING postal code values would a particular class of business be affected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a40bfd",
   "metadata": {
    "scrolled": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "missing_zip_address_count = ...\n",
    "missing_zip_address_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798904e8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(missing_zip_address_count) == pd.Series)\n",
    "assert(missing_zip_address_count['3914 Judah St'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae96f90",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a9e92",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 2e\n",
    "\n",
    "Examine the `invalid_zip_bus` dataframe we computed above and look at the businesses that DO NOT have the special MISSING ZIP code value. Some of the invalid postal codes are just the full 9 digit code rather than the first 5 digits. Create a new column named `postal5` in the original `bus` dataframe which contains only the first 5 digits of the `postal_code` column.\n",
    "\n",
    "Then, for any of the `postal5` ZIP code entries that were not a valid San Fransisco ZIP Code (according to `valid_zips`), the provided code will set the `postal5` value to `None`.  \n",
    "\n",
    "**Do not modify the provided code!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811284a",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "bus['postal5'] = ...\n",
    "\n",
    "\n",
    "bus.loc[~bus['postal5'].isin(valid_zips), 'postal5'] = None\n",
    "# Checking the corrected postal5 column\n",
    "bus.loc[invalid_zip_bus.index, ['bid', 'name', 'postal_code', 'postal5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055e27c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert('postal5' in bus.columns) \n",
    "assert((bus['postal5'].str.len() != 5).sum() == 221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db624b4a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a6984",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "# 3: Investigate the Inspection Data\n",
    "\n",
    "Let's now turn to the inspection DataFrame. Earlier, we found that `ins` has 4 columns named \n",
    "`iid`, `score`, `date` and `type`.  In this section, we determine the granularity of `ins` and investigate the kinds of information provided for the inspections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a63776",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-174ed23c543ad9da",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's start by looking again at the first 5 rows of `ins` to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5687f44",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f0fbe724a2783e33",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ins.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd6863",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3a\n",
    "\n",
    "The column `iid` probably corresponds to an inspection id.  Is it a primary key?  Write an expression (line of code) that evaluates to `True` or `False` based on whether all the values are unique.\n",
    "\n",
    "**Hint:** This is a very similar question to Question 1a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adea110",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "is_ins_iid_a_primary_key = ...\n",
    "print(is_ins_iid_a_primary_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5de1c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(is_ins_iid_a_primary_key) == bool or type(is_ins_iid_a_primary_key) == np.bool) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b96bc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5b214",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3b\n",
    "\n",
    "The column `iid` appears to be the composition of two numbers and the first number looks like a business id.  \n",
    "\n",
    "**Part 1.**: Create a new column called `bid` in the `ins` dataframe containing just the business id.  You will want to use `ins['iid'].str` operations to do this.  Also be sure to convert the type of this column to `int`\n",
    "\n",
    "**Part 2.**: Then compute how many values in this new column are invalid business ids (i.e. do not appear in the `bus['bid']` column). This is verifying a foreign key relationship. Consider using the `pd.Series.isin` function.\n",
    "\n",
    "\n",
    "**No python `for` loops or list comprehensions required!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351fa470",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ce5bd",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd920c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert('bid' in ins.columns) \n",
    "assert(ins['bid'].dtype == int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d9b2d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3bi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a31d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Part 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e63e6",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "invalid_bid_count = ...\n",
    "\n",
    "print(invalid_bid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41005c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(invalid_bid_count == 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adffea6c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3bii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c78186",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3c\n",
    "\n",
    "What if we are interested in a time component of the inspection data?  We need to examine the date column of each inspection. \n",
    "\n",
    "**Part 1:** What is the type of the individual `ins['date']` entries? You may want to grab the very first entry and use the `type` function in python. \n",
    "\n",
    "**Part 2:** Use `pd.to_datetime` to create a new `ins['timestamp']` column containing of `pd.Timestamp` objects.  These will allow us to do more date manipulation.\n",
    "\n",
    "**Part 3:** What are the earliest and latest dates in our inspection data?  *Hint: you can use `min` and `max` on dates of the correct type.*\n",
    "\n",
    "**Part 4:** We probably want to examine the inspections by year. Create an additional `ins['year']` column containing just the year of the inspection.  Consider using `pd.Series.dt.year` to do this.  \n",
    "\n",
    "**Note: If you get a `SettingWithCopyWarning`, consider using the [`assign` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html) to add a column to a DataFrame.**\n",
    "\n",
    "**No python `for` loops or list comprehensions required!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1f1cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86910b1",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ins_date_type = ...\n",
    "ins_date_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f007f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(ins_date_type) == type) \n",
    "assert(ins_date_type in [type(\"str\"), type(\"int\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025f3bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3ci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a04d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Part 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3390297",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c6cd5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(ins['timestamp'][1]) == pd.Timestamp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6ac4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3cii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fb85c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Part 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce12e2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "earliest_date = ...\n",
    "latest_date = ...\n",
    "\n",
    "print(\"Earliest Date:\", earliest_date)\n",
    "print(\"Latest Date:\", latest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f6855",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(earliest_date) == pd.Timestamp) \n",
    "assert(type(latest_date) == pd.Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00c4cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3ciii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd04ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Part 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a27b2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fce27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert('year' in ins.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884468e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3civ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4bfc39",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "# 4: Joining Data Across Tables\n",
    "\n",
    "In this question we will start to connect data across mulitple tables.  We will be using the `merge` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af766e",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 4a\n",
    "\n",
    "Let's figure out which restaurants had the lowest scores. Before we proceed, let's filter out missing scores from `ins` so that negative scores don't influence our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = ins[ins[\"score\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc798ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "We'll start by creating a new dataframe called `ins_named`. It should be exactly the same as `ins`, except that it should have the name and address of every business, as determined by the `bus` dataframe. If a `business_id` in `ins` does not exist in `bus`, the name and address should be given as `NaN`. \n",
    "\n",
    "*Hint*: Use the merge method to join the `ins` dataframe with the appropriate portion of the `bus` dataframe. See the official [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) on how to use `merge`.\n",
    "\n",
    "*Note*: For quick reference, a pandas 'left' join keeps the keys from the left frame, so if `ins` is the left frame, all the keys from `ins` are kept and if a set of these keys don't have matches in the other frame, the columns from the other frame for these \"unmatched\" key rows contains NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597902eb",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ins_named = ...\n",
    "\n",
    "\n",
    "ins_named.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30325fa8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(\"name\" in ins_named and \"address\" in ins_named) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf1396",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3af9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 4b\n",
    "\n",
    "Let's look at the 20 businesses with the lowest **median** score.  Order your results by the median score followed by the business name to break ties. The resulting table should look like:\n",
    "\n",
    "\n",
    "*Hint: You may find the `as_index` argument in the `groupby` method important*. [The documentation is linked here!](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th>bid</th>      <th>name</th>      <th>median score</th>    </tr>  </thead>  <tbody>    <tr>      <th>84590</th>      <td>Chaat Corner</td>      <td>54.0</td>    </tr>    <tr>        <th>90622</th>      <td>Taqueria Lolita</td>      <td>57.0</td>    </tr>    <tr>         <th>94351</th>      <td>VBowls LLC</td>      <td>58.0</td>    </tr>    <tr>          <th>69282</th>      <td>New Jumbo Seafood Restaurant</td>      <td>60.5</td>    </tr>    <tr>         <th>1154</th>      <td>SUNFLOWER RESTAURANT</td>      <td>63.5</td>    </tr>  <tr>          <th>93150</th>      <td>Chez Beesen</td>      <td>64.0</td>    </tr>   <tr>     <th>39776</th>      <td>Duc Loi Supermarket</td>      <td>64.0</td>    </tr>  <tr>         <th>78328</th>      <td>Golden Wok</td>      <td>64.0</td>    </tr>  <tr>          <th>69397</th>      <td>Minna SF Group LLC</td>      <td>64.0</td>    </tr>     <tr>        <th>93502</th>      <td>Smoky Man</td>      <td>64.0</td>    </tr>    <tr>           <th>98995</th>      <td>Vallarta's Taco Bar</td>      <td>64.0</td>    </tr>    <tr>         <th>10877</th>      <td>CHINA FIRST INC.</td>      <td>64.5</td>    </tr>    <tr>        <th>71310</th>      <td>Golden King Vietnamese Restaurant</td>      <td>64.5</td>    </tr>     <tr>          <th>89070</th>      <td>Lafayette Coffee Shop</td>      <td>64.5</td>    </tr>\n",
    "    <tr>          <th>71008</th>      <td>House of Pancakes</td>      <td>65.0</td>    </tr> <tr>         <th>2542</th>      <td>PETER D'S RESTAURANT</td>      <td>65.0</td>    </tr>            <tr>        <th>3862</th>      <td>IMPERIAL GARDEN SEAFOOD RESTAURANT</td>      <td>66.0</td>    </tr>    <tr>         <th>61427</th>      <td>Nick's Foods</td>      <td>66.0</td>    </tr>    <tr>          <th>72176</th>      <td>Wolfes Lunch</td>      <td>66.0</td>    </tr>    <tr>        <th>89141</th>      <td>Cha Cha Cha on Mission</td>      <td>66.5</td>    </tr>  </tbody></table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cf6cb",
   "metadata": {
    "scrolled": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "twenty_lowest_scoring = ...\n",
    "\n",
    "\n",
    "twenty_lowest_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734db58a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(set(twenty_lowest_scoring.columns) == {'median score', 'name'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49c32d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f544f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 4c\n",
    "\n",
    "Let's figure out which restaurant had the worst score ever (single lowest score). \n",
    "\n",
    "In the cell below, assign `worst_restaurant` to the name of the restaurant with the **lowest inspection score ever**. Feel free to head to yelp.com and look up the reviews page for this restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789420be",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "worst_restaurant = ...\n",
    "worst_restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7925a69",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert(type(worst_restaurant) == str) \n",
    "assert(len(worst_restaurant) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f6bea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260716c",
   "metadata": {
    "otter": {
     "tests": [
      "q0"
     ]
    }
   },
   "source": [
    "## Congratulations! You have finished Assignment 2! ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0": {
     "name": "q0",
     "points": 0,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1a": {
     "name": "q1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert is_bid_unique\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(top_names) == 5\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert top_names[0] == \"Peet's Coffee & Tea\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert q1c in set(['A', 'B', 'C'])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(zip_counts) == pd.Series\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert zip_counts['94103'] == 562\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert q2b in set(['A', 'B', 'C'])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2ci": {
     "name": "q2ci",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (valid_zips.dtype == object) | (valid_zips.dtype == pd.StringDtype())\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert type(valid_zips) == pd.Series\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2cii": {
     "name": "q2cii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(invalid_zip_bus) == pd.DataFrame\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(missing_zip_address_count) == pd.Series\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert missing_zip_address_count['3914 Judah St'] == 1\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2e": {
     "name": "q2e",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'postal5' in bus.columns\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (bus['postal5'].str.len() != 5).sum() == 221\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(is_ins_iid_a_primary_key) == bool or type(is_ins_iid_a_primary_key) == np.bool\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3bi": {
     "name": "q3bi",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'bid' in ins.columns\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ins['bid'].dtype == int\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3bii": {
     "name": "q3bii",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert invalid_bid_count == 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3ci": {
     "name": "q3ci",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(ins_date_type) == type\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ins_date_type in [type('str'), type('int')]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3cii": {
     "name": "q3cii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(ins['timestamp'][1]) == pd.Timestamp\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3ciii": {
     "name": "q3ciii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(earliest_date) == pd.Timestamp\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert type(latest_date) == pd.Timestamp\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3civ": {
     "name": "q3civ",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'year' in ins.columns\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'name' in ins_named and 'address' in ins_named\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert set(twenty_lowest_scoring.columns) == {'median score', 'name'}\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(worst_restaurant) == str\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert len(worst_restaurant) > 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
